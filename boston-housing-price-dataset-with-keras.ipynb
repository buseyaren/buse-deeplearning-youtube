{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This is an example from Deep Learning With Python book.**","metadata":{"_uuid":"452ca30a3ce0a2dc1b59b3f84f0c7f02ccbd7319"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-19T13:26:31.569519Z","iopub.execute_input":"2021-11-19T13:26:31.569986Z","iopub.status.idle":"2021-11-19T13:26:31.575553Z","shell.execute_reply.started":"2021-11-19T13:26:31.569942Z","shell.execute_reply":"2021-11-19T13:26:31.574504Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{"_uuid":"76c00e3b6e596e30ba6728c95ef323389dca5537"}},{"cell_type":"code","source":"from keras.datasets import boston_housing\n\n(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-11-19T13:19:04.846008Z","iopub.execute_input":"2021-11-19T13:19:04.846554Z","iopub.status.idle":"2021-11-19T13:19:05.649446Z","shell.execute_reply.started":"2021-11-19T13:19:04.846507Z","shell.execute_reply":"2021-11-19T13:19:05.648435Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_targets","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:21:19.382190Z","iopub.execute_input":"2021-11-19T13:21:19.382819Z","iopub.status.idle":"2021-11-19T13:21:19.392749Z","shell.execute_reply.started":"2021-11-19T13:21:19.382771Z","shell.execute_reply":"2021-11-19T13:21:19.392040Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_targets","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:21:00.929821Z","iopub.execute_input":"2021-11-19T13:21:00.930131Z","iopub.status.idle":"2021-11-19T13:21:00.938142Z","shell.execute_reply.started":"2021-11-19T13:21:00.930083Z","shell.execute_reply":"2021-11-19T13:21:00.937157Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# take a look at the data\n\nprint(f'Training data : {train_data.shape}')\nprint(f'Test data : {test_data.shape}')\nprint(f'Training sample : {train_data[0]}')\nprint(f'Training target sample : {train_targets[0]}')","metadata":{"_uuid":"46abef54b50bee09d016f30786d79dda2171ad3c","execution":{"iopub.status.busy":"2021-11-19T13:21:39.811687Z","iopub.execute_input":"2021-11-19T13:21:39.812225Z","iopub.status.idle":"2021-11-19T13:21:39.818867Z","shell.execute_reply.started":"2021-11-19T13:21:39.812161Z","shell.execute_reply":"2021-11-19T13:21:39.818165Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the data\n\nWe are going to do a feature normalization . Feature normalizaion is when you subtract the mean of the feature from each feature and divide each result by the standard deviation.\n","metadata":{"_uuid":"06d8318b1e09e6dffb161fab36b324a309b25b6a"}},{"cell_type":"code","source":"mean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data /= std\ntest_data -= mean\ntest_data /= std\n\n# Note that the quantities used for normalizing the test data are computed using the\n# training data. You should never use in your workflow any quantity computed on the\n# test data, even for something as simple as data normalization.","metadata":{"_uuid":"fb47c40e26f4a56384584910c748eea00cfd7159","execution":{"iopub.status.busy":"2021-11-19T13:27:37.882210Z","iopub.execute_input":"2021-11-19T13:27:37.882555Z","iopub.status.idle":"2021-11-19T13:27:37.887511Z","shell.execute_reply.started":"2021-11-19T13:27:37.882469Z","shell.execute_reply":"2021-11-19T13:27:37.886829Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Building the network","metadata":{"_uuid":"26834f67baa2de9d4b516b1f8eaafc5737276fce"}},{"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\ndef build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='rmsprop',\n              loss='mse',\n              metrics=['mae'])\n    return model","metadata":{"_uuid":"4cbaa8646f81bab4261e9c25474cef65b2fc8474","execution":{"iopub.status.busy":"2021-11-19T13:33:21.426630Z","iopub.execute_input":"2021-11-19T13:33:21.427253Z","iopub.status.idle":"2021-11-19T13:33:21.435258Z","shell.execute_reply.started":"2021-11-19T13:33:21.427183Z","shell.execute_reply":"2021-11-19T13:33:21.434610Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## K-fold validation","metadata":{"_uuid":"bddd23bd4517bcbedb3e264249a39cf851a9acfd"}},{"cell_type":"code","source":"k = 4\nnum_val_samples = len(train_data) // k\nnum_epochs = 100\nall_scores = []\n\nfor i in range(k):\n    print(f'Processing fold # {i}')\n    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n    \n    partial_train_data = np.concatenate(\n                            [train_data[:i * num_val_samples],\n                            train_data[(i+1) * num_val_samples:]],\n                            axis=0)\n    partial_train_targets = np.concatenate(\n                            [train_targets[:i * num_val_samples],\n                            train_targets[(i+1)*num_val_samples:]],\n                            axis=0)\n    model = build_model()\n    model.fit(partial_train_data,\n              partial_train_targets,\n              epochs=num_epochs,\n              batch_size=1,\n              verbose=0)\n    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n    all_scores.append(val_mae)","metadata":{"_uuid":"e9ccbfd3c006f5a51da9e83809f601cf651c02dc","execution":{"iopub.status.busy":"2021-11-19T13:46:19.400353Z","iopub.execute_input":"2021-11-19T13:46:19.400719Z","iopub.status.idle":"2021-11-19T13:48:08.984682Z","shell.execute_reply.started":"2021-11-19T13:46:19.400660Z","shell.execute_reply":"2021-11-19T13:48:08.983780Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(f'all_scores : {all_scores}')\nprint(f'mean all scores : {np.mean(all_scores)}')","metadata":{"_uuid":"5a9f7c987f6f29ea22a03c3df0688d9e38ea8f05","execution":{"iopub.status.busy":"2021-11-19T13:49:25.239022Z","iopub.execute_input":"2021-11-19T13:49:25.239503Z","iopub.status.idle":"2021-11-19T13:49:25.244587Z","shell.execute_reply.started":"2021-11-19T13:49:25.239438Z","shell.execute_reply":"2021-11-19T13:49:25.243421Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)","metadata":{"_uuid":"328b6245ae5d964df08f14de6236bc68147c5611","execution":{"iopub.status.busy":"2021-11-19T13:52:22.111841Z","iopub.execute_input":"2021-11-19T13:52:22.112462Z","iopub.status.idle":"2021-11-19T13:52:24.844362Z","shell.execute_reply.started":"2021-11-19T13:52:22.112214Z","shell.execute_reply":"2021-11-19T13:52:24.843480Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"test_mae_score","metadata":{"_uuid":"174d90326f6ed72d9127f6cf8d0619a4820d56e5","execution":{"iopub.status.busy":"2021-11-19T13:59:10.045069Z","iopub.execute_input":"2021-11-19T13:59:10.045798Z","iopub.status.idle":"2021-11-19T13:59:10.052261Z","shell.execute_reply.started":"2021-11-19T13:59:10.045379Z","shell.execute_reply":"2021-11-19T13:59:10.051559Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}